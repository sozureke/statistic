{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b684b-b62a-4017-9acc-f1118b5eb2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "872d1661-a920-4b4d-bd33-1035aa825f5c",
   "metadata": {},
   "source": [
    "# TP2 - Linear Correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841818d9-8bd0-4b73-97f3-5165932a1d03",
   "metadata": {},
   "source": [
    "Estimated time: **1.5** hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717403c-90a4-4202-a285-fd74125d75a5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this lab, you'll go over hands-on exercises using Python to further consolidate your understanding about linear correlation, in particular the Pearson's Correlation Coefficient, and the visualization by means of scatterplot, hexagonal binning plot, correlation matrix and heatmap. Besides, you will explore serial correlation in time series using autocorrelation. Last, we will practice the calculation of confidence interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157adf8-92c5-4263-861d-bce926a33a0c",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51d720-bae6-4b96-9d4b-58c04dbaa551",
   "metadata": {},
   "source": [
    "* Get familiar with the dataset\n",
    "* Sample exercises\n",
    "  * Correlation: Pearson's Correlation Coefficient (PCC), scatterplot, hexagonal binning plot, correlation matrix, and heatmap\n",
    "  * Autocorrelation & Partial autocorrelation\n",
    "  * Confidence interval\n",
    "* Assignment questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8047d-1862-49d2-921e-1be83f2e2946",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05b8d9-2cb4-4197-b37b-b61638d90d14",
   "metadata": {},
   "source": [
    "# Get familiar with the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61756875-142d-448b-b506-65060c0baf7f",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf4f4d-a78d-4ad4-89b8-1121b32b25ac",
   "metadata": {},
   "source": [
    "All libraries required for this lab are listed below. If you don't have those libraries installed on your machine, you may need to uncomment and install certain libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24837a3-944a-4f02-99fd-2ba2a88caf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas seaborn==0.13 matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22beecf6-1d1e-4f95-8bb7-dd2f4a4050dd",
   "metadata": {},
   "source": [
    "Import the libraries needed for the lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff290177-5e3a-4617-a239-493390ed8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0842b5-e6bf-471f-bfcc-beb952e0e54f",
   "metadata": {},
   "source": [
    "Read in the csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96e7f6-89f1-4f8a-9ee2-ea7ee1f2b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('university_ranking.csv',encoding='latin-1')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386b9ef-71d6-42b3-86a5-5516c6c13a3e",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "#### The dataset contains the Times Higher Education World University Rankings 2016-2024, which include more than 1,900 universities across more than 100 countries and regions. The individual field of the dataset is explained below and more information can be found at https://www.timeshighereducation.com/sites/default/files/the_2024_world_university_rankings_methodology.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d193278b-fdfc-43be-8f30-4d7d2c8c00c6",
   "metadata": {},
   "source": [
    "| Column Name               | Description                                                                                                                                 |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Rank**                   | The ranking of the university based on the Overall Score.                                |\n",
    "| **Name**                   | The name of the university.                                                                                                                |\n",
    "| **Country**                | The country where the university is located.                                                                                               |\n",
    "| **Student Population**      | The number of full-time-equivalent students at the university in a certain year.                                                                                  |\n",
    "| **Students to Staff Ratio** | The ratio of full-time-equivalent students to the number of academic staff, those involved in teaching or research.                              |\n",
    "| **International Students**  | The percentage of students originating from outside the country of the university.                                                             |\n",
    "| **Female to Male Ratio**    | The ratio of female to male students at the university.                                                      |\n",
    "| **Overall Score**           | A composite score representing the overall performance of the university computed based on various performance indicators.                   |\n",
    "| **Teaching**                | A score representing the university's teaching, which may include factors like teaching reputation, student staff ratio, doctorate bachelor ratio, doctorate staff ratio           |\n",
    "| **Research Environment**    | A score representing the univiersity's research environment, which may include factors like reserach reputation, research income, research productivity.                           |\n",
    "| **Research Quality**        | A score representing the university's research quality, which may include factors like citation impact, research strength, research excellence, and research influence.       |\n",
    "| **Industry Impact**         | A score representing the university’s industry impact,  which may include factors like industry income, patents                    |\n",
    "| **International Outlook**   | A score representing the university's global outlook, which may include factors like  international students, international staff, international co-authorship, etc.                   |\n",
    "| **Year**                    | The year of the data.                                                                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac67dd92-9ecc-43ce-85cf-7dccc6455ca6",
   "metadata": {},
   "source": [
    "### Display the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5fbc5-7b88-4cdd-9533-c9c640c54c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf09e1-0dec-4081-9b4a-24a0a158f50d",
   "metadata": {},
   "source": [
    "#### Get info about the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e604e-11d2-42f4-8738-a075eab5339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a017e36-b1b7-436e-a041-cf07c857eb6a",
   "metadata": {},
   "source": [
    "#### Get the data related to University of Luxembourg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5c668-dca9-4016-84fa-c94b16446d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniLU = df[df['Name']=='University of Luxembourg'].set_index('Year')\n",
    "uniLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c3e2a-42cb-4b1d-a357-bd7f55ab84ba",
   "metadata": {},
   "source": [
    "#### Get the data related to Oxford University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73faed97-8a23-4cb7-86c1-dbfcf49c3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "oxford = df[df['Name']=='University of Oxford'].set_index('Year')\n",
    "oxford"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0448b045-024b-4a7c-94ea-c1b9adfbaf7b",
   "metadata": {},
   "source": [
    "#### The \"International Students\" column contains percentage value which is represented as a string, convert it to decimal value to prepare for the following exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f971b-aab8-4f37-a9e3-cb65245ac9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the 'International Students' column contains a '%' symbol\n",
    "if df['International Students'].str.contains('%').any():\n",
    "    # If it contains '%', strip the '%' and convert to numeric\n",
    "    df['International Students'] = pd.to_numeric(df['International Students'].str.rstrip('%'), errors='coerce') / 100.0\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f0c5d-3241-45c5-a30a-ba353d7f2762",
   "metadata": {},
   "source": [
    "## Sample exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908bd52-5d32-49fd-9648-76850eb03eba",
   "metadata": {},
   "source": [
    "### Example-1: compute the Pearson's Correlation Coefficient (PCC) between Overall Score and Teaching using the formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0381daef-ad1b-4567-916f-1d0e26d6e783",
   "metadata": {},
   "source": [
    "The **Pearson's Correlation Coefficient** is calculated as:\n",
    "\n",
    "$$\n",
    "\\textcolor{blue}{\\Large r = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}}\n",
    "$$\n",
    "\n",
    "where <br>\n",
    "- $\\text{Cov(X,Y)}$ is the covariance between $X$ and $Y$ <br>\n",
    "- $\\sigma_X$ is the standard deviation of $X$ <br>\n",
    "- $\\sigma_Y$ is the standard deviation of $Y$ <br>\n",
    "\n",
    "More specifically, \n",
    "$$ \n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\text{Cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y}) \\\\ \\\\\n",
    "\\text{Variance(X)} \\quad = \\quad \\frac{\\sum_{i=1}^{n} (X_i - \\bar{X})^2}{n}  \\\\ \\\\\n",
    "\\text{Standard deviation}  \\quad \\sigma_X \\quad = \\quad \\sqrt{\\text{Variance(X)}} \\\\ \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Hence, \n",
    "$$\n",
    "\\Large r = \\frac{\\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum_{i=1}^{n} (X_i - \\bar{X})^2} \\sqrt{\\sum_{i=1}^{n} (Y_i - \\bar{Y})^2}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f3d0d-280a-4fb9-9add-dfd959027888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute covariance between 'Overall Score' and 'Teaching'\n",
    "covariance = df['Overall Score'].cov(df['Teaching'])\n",
    "\n",
    "# Compute standard deviation of 'Overall Score'\n",
    "std_overall_score = df['Overall Score'].std()\n",
    "\n",
    "# Compute standard deviation of 'Teaching'\n",
    "std_teaching = df['Teaching'].std()\n",
    "\n",
    "# Compute the Pearson's Correlation Coefficient (PCC) using covariance and standard deviations\n",
    "correlation_coefficient = covariance / (std_overall_score * std_teaching)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Covariance between Overall Score and Teaching: {covariance}\")\n",
    "print(f\"Standard deviation of Overall Score: {std_overall_score}\")\n",
    "print(f\"Standard deviation of Teaching: {std_teaching}\")\n",
    "print(f\"Pearson's Correlation Coefficient (calculated manually): {correlation_coefficient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdff186-6c00-40db-923e-91d82c94b3b2",
   "metadata": {},
   "source": [
    "### Example-2: compute the Pearson's Correlation Coefficient (PCC) between Overall Score and Teaching using the built-in corr() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e26c6-c4e8-4bbc-94c4-2d7ab39047ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Pearson's Correlation Coefficient (PCC) between 'Overall Score' and 'Teaching'\n",
    "correlation = df['Overall Score'].corr(df['Teaching'])\n",
    "\n",
    "# Output the result\n",
    "print(f\"Correlation coefficient between Overall Score and Teaching is: {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894c588-7e5f-4db1-a7a2-75a501f039ba",
   "metadata": {},
   "source": [
    "### Example-3: use scatterplot and the hexagonal binning plot to visualize the correlation between Overall Score and Teaching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6855f4-2be9-4057-a175-e831544cf4c8",
   "metadata": {},
   "source": [
    "#### Scatterplot is commonly used to conduct visual exploration of possible correlation between variables. With respect to scatterplot, the hexagonal binning plot comes handy for large datasets, as it can differentiate the density of data points in each hexagon by means of color density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8fc275-b705-48b1-a85b-9aeb215b0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Generate scatter plot using Seaborn\n",
    "sns.scatterplot(x='Teaching', y='Overall Score', data=df, ax=ax1)\n",
    "ax1.set_title('Scatter Plot: Overall Score vs Teaching')\n",
    "ax1.set_xlabel('Teaching')\n",
    "ax1.set_ylabel('Overall Score')\n",
    "\n",
    "# Generate the hexagonal binning plot using Matplotlib hexbin() function: \n",
    "# - gridsize specifies the number of hexagons across the x-axis\n",
    "# - cmap indicates the color map to be used for the hexagons. 'Reds' means the hexagons will be \n",
    "#   shaded using a red gradient where darker shades represent higher densities of points.\n",
    "# - mincnt=1 ensures that hexagons with at least 1 point will be colored. If a hexagon has fewer \n",
    "#   points than the specified threshold, it will not be shown.\n",
    "hb = ax2.hexbin(x='Teaching', y='Overall Score', data=df, gridsize=20, cmap='Reds', mincnt=1)\n",
    "ax2.set_title('Hexbin Plot: Overall Score vs Teaching')\n",
    "ax2.set_xlabel('Teaching')\n",
    "ax2.set_ylabel('Overall Score')\n",
    "# Add a color bar to the plot, providing a legend for the hexbin counts\n",
    "fig.colorbar(hb, ax=ax2, label='Count')\n",
    "\n",
    "# Show both plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e6105-13d4-4ce4-9744-94d71e8660e8",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "- According to the scatterplot on the left, we can see that as the value of Teaching increases, the value of the Overall Score also tends to increase, which indicates a positive correlation between them. The Pearson's Correlation Coefficient (PCC) computed before gives a more precise idea of the correlation between the two.\n",
    "- As shown on the right figure, the hexagons in darker red indicates that there are more universities have an Overall Score around 20 with a Teaching score around 20. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbee80-7261-4759-8a2f-cf3a333e9718",
   "metadata": {},
   "source": [
    "#### Generate the scatter plot with the linear regression line using the linear regression model from scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6bf7e-e3c4-4a50-aba5-c2ee8daf95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# Perform linear regression between 'Teaching' and 'Overall Score'\n",
    "# The result includes slope, intercept, r-value, p-value, and standard error.\n",
    "# Here, we only make use of the slope and intercept to show the liner regression line\n",
    "result = linregress(df['Teaching'], df['Overall Score'])\n",
    "predict_overall_score = result.slope * df['Teaching'] + result.intercept\n",
    "\n",
    "# Display the linear regression line over the scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Teaching', y='Overall Score', data=df)\n",
    "plt.plot(df['Teaching'], predict_overall_score, color='red')\n",
    "\n",
    "plt.title('Scatterplot with regression line: Overall Score vs Teaching ')\n",
    "plt.xlabel('Teaching')\n",
    "plt.ylabel('Overall Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa59831-5a48-453e-8f36-526fca413d2d",
   "metadata": {},
   "source": [
    "#### Or we can generate the scatter plot with the linear regression line directly using the Seaborn's regplot() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090771a-a3b0-491f-8044-08b55bfeec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the scatter plot with regression line using Seaborn's regplot() function\n",
    "plt.figure(figsize=(8, 6))\n",
    "# The regplot() function plots data points as scatter plot and fits a regression line over them.\n",
    "# - line_kws parameter customizes the appearance of the regression line. \n",
    "# - scatter_kws customizes the appearance of the scatter points. Here the point size is set to 40, \n",
    "#   the edge color of the scatter point is set to white, and the thickness of the edge is adjusted \n",
    "#   to 0.6 to mimic the same point style as in the above plot.\n",
    "sns.regplot(x='Teaching', y='Overall Score', data=df, line_kws={'color': 'red'}, scatter_kws={'s': 40, 'edgecolor': 'w', 'linewidths': 0.6})  \n",
    "plt.title('Scatterplot with regression line: Overall Score vs Teaching ')\n",
    "plt.xlabel('Teaching')\n",
    "plt.ylabel('Overall Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd95f1-959b-40cc-b631-1fc469a523c9",
   "metadata": {},
   "source": [
    "### Example-4: Pearson's Correlation Coefficient - understand the principle behind normalizing the covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be06d2e-871b-4761-a0b7-8bb4e3ffe2e9",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\large\n",
    "\\begin{align*}\n",
    "\\text{Variance(X)} \\quad = \\quad \\frac{\\sum_{i=1}^{n} (X_i - \\bar{X})^2}{n}  \\\\ \\\\\n",
    "\\text{Standard deviation}  \\quad \\sigma_X \\quad = \\quad \\sqrt{\\text{Variance(X)}} \\\\ \\\\\n",
    "\\text{Cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y}) \\\\ \\\\\n",
    "\\Large r = \\frac{\\text{cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d282f-1496-4476-b054-f9ad65e9a293",
   "metadata": {},
   "source": [
    "#### Compute the covariance between International Outlook and the percentage of International Students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32476845-d24c-49f9-b202-9e81f92225e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a new data frame which contains only the International Students and International Outlook columns\n",
    "new_df_1 = df[['International Students', 'International Outlook']].copy()\n",
    "new_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd1cdb-73b9-49e7-9797-698c96afb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the covariance between the two columns\n",
    "covariance_1 = new_df_1['International Outlook'].cov(new_df_1['International Students'])\n",
    "print(f\"Covariance between International Outlook and International Students is: {covariance_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccf786-eba2-4dcf-8cb1-d4c0c9cd5722",
   "metadata": {},
   "source": [
    "#### Instead of representing the percentage of international students as a floating point value between [0.0, 1.0], we are going to represent it as an integer value between [0, 100]. In other words, scale it up by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58051af1-5a23-45dc-a8d1-ab7ca9981c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_2 = df[['International Students', 'International Outlook']].copy()\n",
    "new_df_2['International Students'] = new_df_2['International Students'] * 100\n",
    "new_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5fd2d-0ce4-41a5-a302-c778a8c5c71e",
   "metadata": {},
   "source": [
    "#### Compute again the covariance between International Outlook and Internation Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fcffe-7cc8-49ee-8139-aa55e037c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the covariance between the two columns\n",
    "covariance_2 = new_df_2['International Outlook'].cov(new_df_2['International Students'])\n",
    "print(f\"Covariance between International Outlook and International Students is: {covariance_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a7d31-c53c-431f-90c3-0817d2cca3ce",
   "metadata": {},
   "source": [
    "#### As we can see, the covariance is now 220.5276496535549, instead of 2.2052764965355482. This is because the value of covariance depends on the scale of the variable, as indicated in the lecture slide and the formula $\\text{Cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})$. The increase in the value of the covariance doesn't mean the international outlook now has a stronger correlation with the percentage of international students, after we change the unit of the variable that we use to represent it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5572d4-1320-4f23-9131-44f5f5b057b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation between the two columns\n",
    "correlation_1 = new_df_1['International Outlook'].corr(new_df_1['International Students'])\n",
    "correlation_2 = new_df_2['International Outlook'].corr(new_df_2['International Students'])\n",
    "print(f\"Correlation between International Outlook and International Students is: {correlation_1}\")\n",
    "print(f\"Correlation between International Outlook and International Students is: {correlation_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fa156-1774-4d0f-9b11-dc7c04769e83",
   "metadata": {},
   "source": [
    "#### Instead, if we compute the correlation between the two variables before and after the scale up of the variable of International Students, the correlation remains the same. \n",
    "\n",
    "#### As we can see, the Pearson's Correlation Coefficient (PCC) removes the effects of the scale of the variables and normalizes the correlation between two variables to a value within the range of [-1, 1] to make it easier to interpret and compare the strength of the relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89592e4e-2b0b-4839-91dd-a29c664e500d",
   "metadata": {},
   "source": [
    "### Example-5: compute the correlation matrix between International Outlook, Student Population, Students to Staff Ratio, and International Students. And generate the heatmap corresponding to the correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1168d-2e40-4e41-ade9-f6c99be86b1d",
   "metadata": {},
   "source": [
    "#### Compute the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d6d89-f924-47d2-879d-97e0f8d3c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns for correlation computation\n",
    "correlation_columns = df[['International Outlook', 'Student Population', 'Students to Staff Ratio', 'International Students']]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = correlation_columns.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0206628c-bc3c-44f4-baae-967a4f599ba0",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The correlation matrix is symmetric along the diagonal, because PCC(X, Y) = PCC(Y,X)\n",
    "- The International Outlook has a **Strong** linear correlation (PCC = 0.810818) with the percentage of International Students. Instead, it has **very weak** or almost **no** linear correlation with the Student Population (PCC=-0.047217) and Students to Staff Ratio (PC=0.007265), which do make sense.\n",
    "- The Student Population has a **Moderate** correlation withe the Students to Staff Ratio (PCC=0.691228). As the Student Population increases, the Students to Staff Ratio also tends to increase. However, this doesn't necessarily increase the percentage of International Students, as their PCC value is -0.094210. This could be because the majority of the students are still local students, or there are other factors (e.g. language barrier) which affects more the precentage of International Students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c48be-49ca-4948-9d46-c18857ac5ef9",
   "metadata": {},
   "source": [
    "#### Generate the heatmap corresponding to the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057bddd-cc76-4392-a285-544e6b6db99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display all the correlation values in the heatmap, seaborn version 0.13 is required\n",
    "!pip install seaborn==0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca516707-34cb-4e22-bbcc-3258feff9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the heatmap corresponding to the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Use the Seaborn heatmap() function to generate the heatmap \n",
    "# corresponding to the correlation matrix.\n",
    "# - annot=True ensures that each cell of the heatmap are annotated\n",
    "# - cmap specifies the colormap to be used\n",
    "# - fmt=.2f specifies the string format used for annotation. \n",
    "#           '.2f': two digits after the decimal point.\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "\n",
    "plt.title('Correlation Heatmap')\n",
    "# Break the xlabels into two lines, and display them in the middle by adjusting 'ticks' and  \n",
    "# horizontally with rotation=0. The alignment is set to center alignment with ha='center'.  \n",
    "xlabels = ['International\\nOutlook', 'Student\\nPopulation', 'Students to \\nStaff Ratio', 'International\\nStudents']\n",
    "plt.xticks(ticks=[x + 0.5 for x in range(len(xlabels))], labels=xlabels, rotation=0, ha='center')\n",
    "# Wrap option is used as a shortcut to wrap the ylabels into 2 lines\n",
    "plt.yticks(wrap=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db738c-fba4-425c-a499-968899db8382",
   "metadata": {},
   "source": [
    "### Example-6: compute the Confidence Interval with the formula. What is the 95% confidence interval for the average \"Teaching\" score?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87fc92be-f830-4ecf-b711-4ab08a40d903",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Large \\hat{\\mu}_n \\pm \\eta \\frac{s_n}{\\sqrt{n}} \n",
    "$$\n",
    "\n",
    "where,\n",
    "- $\\eta$ is a constant that depends on the confidence level $\\gamma$\n",
    "- $s_n$ is the standard deviation of the sample\n",
    "- $n$ is the size of the sample\n",
    "\n",
    "####\n",
    "| Confidence <br> Interval $\\gamma$| **$\\eta$** |\n",
    "|---------------------|--------|\n",
    "| 80%                 | 1.282  |\n",
    "| 85%                 | 1.440  |\n",
    "| **90%**                 | **1.645**  |\n",
    "| **95%**                 | **1.960**  |\n",
    "| **99%**                 | **2.576**  |\n",
    "| 99.5%               | 2.807  |\n",
    "| 99.9%               | 3.291  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697afd0-2f01-4454-a111-327023968e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values for η\n",
    "eta_values = {\n",
    "    '80%': 1.282,\n",
    "    '85%': 1.44,\n",
    "    '90%': 1.645,\n",
    "    '95%': 1.96,\n",
    "    '99%': 2.576,\n",
    "    '99.5%': 2.807,\n",
    "    '99.9%': 3.291\n",
    "}\n",
    "\n",
    "# compute the 95% Confidence Interval for the mean \"Teaching\" score\n",
    "teaching_mean = df['Teaching'].mean() # Sample mean\n",
    "teaching_std = df['Teaching'].std()  # Sample standard deviation\n",
    "n = len(df['Teaching'])  # Number of samples\n",
    "\n",
    "# Use the formula to compute the 95% CI manually\n",
    "margin_of_error = eta_values[\"95%\"]*teaching_std/np.sqrt(n)\n",
    "lower_bound = teaching_mean - margin_of_error\n",
    "upper_bound = teaching_mean + margin_of_error\n",
    "\n",
    "print(f\"95% confidence interval for the average Teaching score is: ({lower_bound}, {upper_bound})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210016d8-a55a-4fd5-bf4a-9db2bffe7cd8",
   "metadata": {},
   "source": [
    "### Example-7: compute and visualize the 90%, 95%, 99% confidence interval for the average \"Teaching\" score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b47d7-7265-4a23-95d8-4a1fff20050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean and standard error\n",
    "teaching_mean = df['Teaching'].mean()\n",
    "teaching_std = df['Teaching'].std()\n",
    "\n",
    "confidence_levels = [\"90%\", \"95%\", \"99%\"]\n",
    "confidence_intervals = []\n",
    "\n",
    "# Calculating confidence intervals for 90%, 95%, and 99%\n",
    "for cl in confidence_levels:\n",
    "    margin_of_error = eta_values[cl]*teaching_std/np.sqrt(n)\n",
    "    lower_bound = teaching_mean - margin_of_error\n",
    "    upper_bound = teaching_mean + margin_of_error\n",
    "    confidence_intervals.append((lower_bound, upper_bound))\n",
    "    \n",
    "\n",
    "# Plotting the confidence intervals with Teaching Score on the x-axis and Confidence Level on the y-axis\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.errorbar(\n",
    "    # Creates a list with the same teaching mean value repeated for each confidence level \n",
    "    x=[teaching_mean] * len(confidence_intervals), y=['90%', '95%', '99%'],\n",
    "    # The size of the error bar is the margin of error \n",
    "    xerr=[(upper_bound - lower_bound) / 2 for lower_bound, upper_bound in confidence_intervals], \n",
    "    # Display the mean as a point (fmt=o), display the markers and error bars in blue (color='b'),  \n",
    "    # specify the width of the \"caps\" at the end of the error bars (capsize=10)\n",
    "    fmt='o', color='b', capsize=10\n",
    ")\n",
    "\n",
    "# Adding a vertical line for the mean Teaching score\n",
    "plt.axvline(x=teaching_mean, color='r', linestyle='--', label=f'Mean Teaching Score: {teaching_mean:.2f}')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Confidence Intervals for Teaching Score')\n",
    "plt.xlabel('Teaching Score')\n",
    "plt.ylabel('Confidence Level')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbd9137-9444-40f3-906e-2d7731475563",
   "metadata": {},
   "source": [
    "#### The above figure show the confidence intervals computed for the Teaching score for each confidence level (90%, 95%, 99%) horizontally. The mean value for the Teaching score is shown as a point in the middle for the confidence interval, and the lower and upper bound are shown as the cap at the end of the error bars.  \n",
    "\n",
    "#### Observation: Higher confidence levels will increase the width of the confidence intervals, as indicated in the lecture slide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547a04e-d36c-483a-8b98-e29227443c4a",
   "metadata": {},
   "source": [
    "### Example-8: compute and visualize the 95% confidence interval for the average \"Teaching\" score for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132f6da-80a6-47dc-94eb-46770026ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overall mean for the Teaching score across different years\n",
    "overall_mean = df['Teaching'].mean()\n",
    "\n",
    "# Obtain the unique year values\n",
    "years = df['Year'].unique()\n",
    "confidence_intervals = []\n",
    "means = []\n",
    "\n",
    "# Loop through each year to compute the mean and confidence interval\n",
    "for year in years:\n",
    "    annual_data = df[df['Year'] == year]['Teaching']\n",
    "    teaching_annual_mean = annual_data.mean()\n",
    "    teaching_annual_std = annual_data.std()\n",
    "    n = len(annual_data)\n",
    "    \n",
    "    # Compute the 95% confidence interval\n",
    "    margin_of_error = eta_values[\"95%\"] * teaching_annual_std / np.sqrt(n)\n",
    "    lower_bound = teaching_annual_mean - margin_of_error\n",
    "    upper_bound = teaching_annual_mean + margin_of_error\n",
    "    confidence_intervals.append((lower_bound, upper_bound))\n",
    "    \n",
    "    means.append(teaching_annual_mean)\n",
    "\n",
    "print(\"Years: \", years)\n",
    "print(\"Means: \", means)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the confidence intervals for each year\n",
    "for i, (mean, (lower_bound, upper_bound)) in enumerate(zip(means, confidence_intervals)):\n",
    "    plt.errorbar(x=mean, y=i, xerr=(upper_bound - lower_bound) / 2,\n",
    "                 fmt='o', color='green', capsize=5, label='Confidence Interval' if i == 0 else \"\")\n",
    "\n",
    "    # Highlight the overall mean and whether it falls within the interval\n",
    "    if lower_bound <= overall_mean <= upper_bound:\n",
    "        # If so, plot as a blue point\n",
    "        plt.plot(overall_mean, i, 'bo')\n",
    "    else:\n",
    "        # Else, plot as a red cross\n",
    "        plt.plot(overall_mean, i, 'rx', label='Does not contain Overall Mean' if i == 0 else \"\")\n",
    "\n",
    "# Add vertical line for overall mean\n",
    "plt.axvline(x=overall_mean, color='blue', linestyle='--', label='Overall Mean (not the true population mean)')\n",
    "\n",
    "# Set labels and title\n",
    "plt.yticks(range(len(years)), years)\n",
    "plt.xlabel('Teaching Score')\n",
    "plt.ylabel('Year')\n",
    "plt.title('Confidence Intervals for Teaching Scores by Year')\n",
    "\n",
    "# Show legend and plot\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406d513-b0a7-4a87-a3c4-f0a7b588edc2",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "#### - As we can see, the average Teaching score varies a lot from year to year, it decreases year by year from 2016 to 2023 and increases again in 2024.\n",
    "#### - The confidence interval for 2016 is much wider than 2023, even though here the same confidence level 95% is used. Think about what could be the possible reason behind, given the confidence interval is computed as $\\hat{\\mu}_n \\pm \\eta \\frac{s_n}{\\sqrt{n}}$\n",
    "#### - Pay attention here, we show the overall mean value for the Teaching score across different years as a vertical line. **It doesn't represent the true population mean**. The only goal here is to mimic the visualization as lecture slide #5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74540e76-d27b-4217-9193-9b092155c789",
   "metadata": {},
   "source": [
    "### Example-9: Autocorrelation and Partial Autocorrelation analysis for Amazon stock price in the past 5 years, with a lag of up to 24 months in the past"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7e7cf-b9be-4802-a414-dbbfa019f5b3",
   "metadata": {},
   "source": [
    "#### Install the required Python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b5306-0356-4fc4-9e8a-a61a28d405eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Python package yfinance, which allows to access historical market data from Yahoo Finance.\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9a1ba-0a0d-4890-94a4-609f19deb273",
   "metadata": {},
   "source": [
    "#### Obtain the Amazon past 5 year stock price, with an interval of 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d7879-83d0-4600-8c65-d9037fb84e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Retrieve the past 5 years of Amazon stock price data with an interval of 1 month.\n",
    "ticker = 'AMZN' \n",
    "amazon_stock_data = yf.download(ticker, period='5y', interval='1mo')\n",
    "\n",
    "# Select the 'Close' price for analysis\n",
    "amazon_close_price = amazon_stock_data['Close']\n",
    "print(amazon_close_price)\n",
    "\n",
    "# Plot the stock price trend over the past 5 years\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(amazon_close_price, label='Amazon Close Price')\n",
    "plt.title('Amazon Stock Price (Past 5 Years)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3338536-08c4-4381-8b8c-e74edd2262fb",
   "metadata": {},
   "source": [
    "#### Plot the autocorrelation and partial autocorrelation with a lag of up to 24 months using the plot_acf() and plot_pacf() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1245de-2197-4eee-897e-808732363f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Set up the figure and two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plotting the autocorrelation with a lag up to 24 months\n",
    "plot_acf(amazon_close_price, lags=24, ax=ax1)\n",
    "ax1.set_title('Autocorrelation of Amazon Stock Price')\n",
    "ax1.set_xlabel('Lags')\n",
    "ax1.set_ylabel('Autocorrelation')\n",
    "\n",
    "# Plotting the partial autocorrelation with a lag up to 24 months\n",
    "plot_pacf(amazon_close_price, lags=24, ax=ax2)\n",
    "ax2.set_title('Partial Autocorrelation of Amazon Stock Price')\n",
    "ax2.set_xlabel('Lags')\n",
    "ax2.set_ylabel('Partial Autocorrelation')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5f3427e-841b-46c6-ba47-e81e1e117380",
   "metadata": {},
   "source": [
    "#### The above plots display the autocorrelation (left) and partial autocorrelation (right) for the Amazon stock price in the past 5 years with a lag of up to 24 months. The vertical line displays the autocorrelation or partial autocorrelation value. The shaded blue area represents the 95% confidence level. \n",
    "\n",
    "#### Autocorrelations that fall outside these intervals are considered statistically significant: “there is only a 5% chance that this correlation occurred by random chance”\u000b",
    "\n",
    "\n",
    "#### Obervations:\n",
    "\n",
    "**The autocorrelation plot (left one)**\n",
    "- **Positive correlations at lower lags**: The first few lags (up to around lag 5) show strong to moderate positive correlation with statistical significance, indicating that the current stock price is correlated with its past 1 to 4 months price.\n",
    "- **Decreasing trend and negative correlations at higher lags**: The autocorrelation gradually decreases and crosses zero after a few lags, indicating that the relationship weakens as time evolves. From lag 10 on, negative correlations appear, indicating some potential reversal in the stock price.\n",
    "\n",
    "  \n",
    "**The autocorrelation plot (right one)**\n",
    "- **Significant PACF at lag 1**: A strong partial autocorrelation at lag 1 indicates that the first lag has the most substantial influence on the stock's next month price. This means that the stock price from one month ago is directly useful in predicting the current price. After the first lag, the PACF values are much smaller and mostly lie within the confidence interval, suggesting that beyond the first lag, there is little direct influence of past prices on future prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f20403-ad1c-42dd-b028-0213aba642be",
   "metadata": {},
   "source": [
    "## Assignment questions (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14886c55-3653-4368-bbf9-246e1dbdf71d",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">[4 Points]</span> Question 1: among the five factors (Teaching, Research Environment, Research Quality, Industry Impact, International Outlook), identify which variable(s) have strong correlation with the Overall Score by computing the correlation matrix? Among the five factors, identify also a pair of variables that has weak correlation. Generate also the heatmap also corresponding to the correlation matrix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de4733-c1b0-4061-98e0-0b28d8af4bba",
   "metadata": {},
   "source": [
    "#### Question 1-1: compute the correlation matrix between Overall Score, Research Environment, Research Quality, Industry Impact, International Outlook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e4634-4267-46fe-94de-9e49875dd329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e09d20-207d-42cc-a065-5392c425f46a",
   "metadata": {},
   "source": [
    "#### Question 1-2: generate the heatmap based on the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd2074-7274-4460-9926-d9664958ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1f33e-c96c-4a29-85aa-6a26495de887",
   "metadata": {},
   "source": [
    "#### Question 1-3: among the five factors (Teaching, Research Environment, Research Quality, Industry Impact, International Outlook), identify which variable(s) have strong correlation with the Overall Score. Explain why. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402ccb5-5743-4872-9517-704ca8acf412",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066e525-4fe9-4a61-a187-19cbcb470dc0",
   "metadata": {},
   "source": [
    "#### Question 1-4: among the five factors, identify also a pair of variables that has weak correlation. Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13136141-15bc-497a-a1fc-09a47df9c424",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd42af7-cc2c-4cde-8cd3-4007b696ee3a",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">[3 Points]</span> Question-2: Visualize the correlation between the following 3 pairs of variables using scatterplot with linear regression line:\n",
    "### 1) Teaching (x-axis) and Research Environment (y-axis)\n",
    "### 2) Research Environment (x-axis) and Industry Impact (y-axis)\n",
    "### 3) International Outlook (x-axis) and Industry Impact (y-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cee5c9-f9c6-4666-985d-a117ad72ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da08f1-909b-42f3-bfd2-8f31380ab142",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">[5 Points]</span> Question-3: does the average research quality differ significantly for universities in US, France, Germany, Belgium, and Netherland. Compute the 95% confidence intervals for each of them, and visualize them in a figure. What's your observation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f985a-2e67-4ee4-9eca-0c08bdb84b13",
   "metadata": {},
   "source": [
    "#### Question 3-1: Add your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b235e0b-c73c-472f-b573-1bc4ee844dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c28bf-e53f-434d-97b2-d0522087409a",
   "metadata": {},
   "source": [
    "#### Question 3-2: What is your observation based on the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a70ca1e-f5d3-4697-94ac-a6c6c62bfcf3",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63700a4c-55de-479e-8b0f-ace384018434",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">[5 Points]</span> Question-4: Derive the python code to compute the autocorrelation based on the formula. And apply it to compute the autocorrelation for lag 1 to 6 for the following given time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153387c9-cd8a-4f7d-a80a-ee41c771e4a9",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large \n",
    "\\rho_k = \\frac{\\sum_{t=1}^{n-k} (x_t - \\bar{x})(x_{t+k} - \\bar{x})}{\\sum_{t=1}^{n} (x_t - \\bar{x})^2}\n",
    "$$\n",
    "\n",
    "#### where \n",
    "#### - $\\rho_k$ is the autocorrelation at lag $k$\n",
    "#### - $x_t$ is the value of the time series at time $t$\n",
    "#### - $x_{t+k}$ is the value of the time series at time $t+k$\n",
    "#### - $\\bar{x}$ is the mean of the time series\n",
    "#### - $n$ is the total number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752a8a2-ecb8-439f-b06b-95b69ad1ce3d",
   "metadata": {},
   "source": [
    "#### The dataset contains the 30 days temperature in September"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f751323-b20d-4693-9eab-01e805a8f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Date': pd.date_range(start='2024-09-01', periods=30, freq='D'),\n",
    "    'Temperature': [15, 16, 14, 15, 17, 18, 19, 20, 18, 17, 16, 15, 15, 16, 18, 19, 20, 21, 19, 18, 17, 16, 15, 14, 15, 16, 17, 18, 19, 20]\n",
    "}\n",
    "temp_df = pd.DataFrame(data)\n",
    "\n",
    "# Set the 'Date' as the index\n",
    "temp_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Extract the temperature series\n",
    "temperature = temp_df['Temperature']\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4df7a-6dcc-497f-9cec-979551dba81f",
   "metadata": {},
   "source": [
    "#### Question 4-1: Derive the function to compute autocorrelation based on the formula. You can use either the template below, or derive your own template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd22065-0c11-4be2-8eb1-8532dd0fda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the autocorrelation value for a given lag\n",
    "def autocorrelation(time_series, lag):\n",
    "    # insert your code to compute autocorrelation based on the formula here \n",
    "    return rho_k\n",
    "\n",
    "\n",
    "for lag in range(1, 7):\n",
    "    autocorr_value = autocorrelation(temperature, lag)\n",
    "    print(f\"Autocorrelation at lag {lag} is: {autocorr_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74720fb9-e34c-4d65-a18a-0be1a3cbbaa2",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">[3 Points]</span> Question 5: Use the plot_acf() function to visualize the autocorrelation among the 30 days temperature, with a lag of up to 10 days. And make the observation based on the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddec08b-a129-49db-83ee-92a8037f6a06",
   "metadata": {},
   "source": [
    "#### Question 5-1: implement the code to visulize the autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee0554-444b-48ff-8434-bfe438303337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23f3d1-fbc8-4b44-9337-c6da34260437",
   "metadata": {},
   "source": [
    "#### Question 5-2: What's your observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383499b3-7d2b-4ff3-8976-15a8073ac11f",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
